{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip as gz\n",
    "import os\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import datetime as DT\n",
    "import numpy as np\n",
    "import itertools\n",
    "from scipy import stats\n",
    "\n",
    "from bokeh.io import show, output_notebook\n",
    "from bokeh.models import FactorRange\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.layouts import column\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV, RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We put ourselves in the position of a manager in charge of a statewide campaign. As part of voter outreach, state and national campaigns typically include targeted mailings. Let's say that we have the resources to send 100,000 such letters. Our goal is to identify 100,000 registered voters who are most likely to be influenced by our campaign letters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Ohio voter file (https://www6.sos.state.oh.us/ords/f?p=VOTERFTP:STWD:::#stwdVtrFiles) contains a wealth of information about registered voters. We will use that data to develop a prediction model to aid in our voter outreach. The data set contains over 8 million entries and over 100 columns, so it takes some time to load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_path = \"Data\"\n",
    "#if not os.path.isdir(data_path):\n",
    "#    os.mkdir(data_path)\n",
    "#if len(os.listdir(data_path)) == 0:\n",
    "#    !wget -O /Data/1.gz https://www6.sos.state.oh.us/ords/f?p=VOTERFTP:DOWNLOAD::FILE:NO:2:P2_PRODUCT_NUMBER:363\n",
    "#    !wget -O /Data/2.gz https://www6.sos.state.oh.us/ords/f?p=VOTERFTP:DOWNLOAD::FILE:NO:2:P2_PRODUCT_NUMBER:364\n",
    "#    !wget -O /Data/3.gz https://www6.sos.state.oh.us/ords/f?p=VOTERFTP:DOWNLOAD::FILE:NO:2:P2_PRODUCT_NUMBER:365\n",
    "#    !wget -O /Data/4.gz https://www6.sos.state.oh.us/ords/f?p=VOTERFTP:DOWNLOAD::FILE:NO:2:P2_PRODUCT_NUMBER:366"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data\"\n",
    "files = [os.path.join(data_path, file) for file in os.listdir(data_path) \n",
    "         if os.path.isfile(os.path.join(data_path, file)) and file.endswith(\".gz\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = []\n",
    "for file in files:\n",
    "    with gz.open(file, \"r\") as z:\n",
    "        file_content = z.read().decode(\"utf-8\", errors='ignore')\n",
    "        csv_files.append(file_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(StringIO(csv_file), index_col=None, header=0)\n",
    "    df_list.append(df)\n",
    "    \n",
    "df = pd.concat(df_list, axis = 0, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced = df.iloc[:, [1, 3 , 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 31, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107]]\n",
    "df_reduced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Development only\n",
    "df_reduced = df_reduced.sample(n=1000000, replace=False)\n",
    "\n",
    "now = pd.Timestamp(DT.datetime.now())\n",
    "df_reduced['DATE_OF_BIRTH'] = pd.to_datetime(df['DATE_OF_BIRTH'])\n",
    "df_reduced['REGISTRATION_DATE'] = pd.to_datetime(df['REGISTRATION_DATE'])\n",
    "df_reduced['DATE_OF_BIRTH'] = df_reduced['DATE_OF_BIRTH'].where(df_reduced['DATE_OF_BIRTH'] < now, df_reduced['DATE_OF_BIRTH'] -  np.timedelta64(100, 'Y'))\n",
    "df_reduced['REGISTRATION_DATE'] = df_reduced['REGISTRATION_DATE'].where(df_reduced['REGISTRATION_DATE'] < now, df_reduced['REGISTRATION_DATE'] -  np.timedelta64(100, 'Y'))\n",
    "df_reduced['AGE'] = (now - df_reduced['DATE_OF_BIRTH']).astype('<m8[Y]')\n",
    "df_reduced['MONTHS_REGISTERED'] = (now - df_reduced['REGISTRATION_DATE']).astype('<m8[M]')\n",
    "df_reduced = df_reduced[df_reduced['RESIDENTIAL_ZIP'].notnull()]\n",
    "df_reduced['RESIDENTIAL_ZIP'] = df_reduced['RESIDENTIAL_ZIP'].astype(np.int)\n",
    "df_reduced = df_reduced[(np.abs(stats.zscore(df_reduced['AGE'])) < 9)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'AGE' is the only column that could have outliers. The data contained around 300 voters whose ages were over 9 standard deviations from the mean. These rows have been dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add the average income in a voter's zip code as a feature. The average income data is derived from the following data set: https://www.irs.gov/statistics/soi-tax-stats-individual-income-tax-statistics-2016-zip-code-data-soi. While the median income would be a better statistic, it is unfortunately not readily available for the recent years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_df = pd.read_csv(f\"{data_path}/16zpallnoagi.csv\", encoding = \"ISO-8859-1\")\n",
    "income_df.index = income_df['ZIPCODE']\n",
    "income_df['AVG_INCOME'] = income_df['A00200'] * 1000 / income_df['N00200']\n",
    "avg_income = income_df['AVG_INCOME']\n",
    "avg_income.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced = df_reduced[df_reduced[\"RESIDENTIAL_ZIP\"].isin(avg_income.index)]\n",
    "df_reduced[\"AVG_INCOME\"] = df_reduced[\"RESIDENTIAL_ZIP\"].apply(lambda x: avg_income[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The population density is certain to be an important feature in predicting someone's political views, as rural residents are in general more conservative and more likely to vote Republican. The population density by zip code data was obtained here: https://blog.splitwise.com/2014/01/06/free-us-population-density-and-unemployment-rate-by-zip-code/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_density = pd.read_csv(f\"{data_path}/Zipcode-ZCTA-Population-Density-And-Area-Unsorted.csv\", encoding = \"ISO-8859-1\")\n",
    "pop_density['Zip/ZCTA'] = pop_density['Zip/ZCTA'].astype(np.int)\n",
    "pop_density.index = pop_density['Zip/ZCTA']\n",
    "pop_density = pop_density['Density Per Sq Mile']\n",
    "pop_density[pop_density > 0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced = df_reduced[df_reduced[\"RESIDENTIAL_ZIP\"].isin(pop_density.index)]\n",
    "df_reduced[\"POP_DENSITY\"] = df_reduced[\"RESIDENTIAL_ZIP\"].apply(lambda x: pop_density[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voted_primary = df_reduced[df_reduced['PRIMARY-05/08/2018'].isin(['R', 'D']) \n",
    "                           & df_reduced['PRIMARY-05/08/2018'].isin(['R', 'D'])]\n",
    "voted_primary['D'] = df_reduced['PRIMARY-05/08/2018'] == 'D'\n",
    "voted_primary['R'] = df_reduced['PRIMARY-05/08/2018'] == 'R'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voted_primary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A bit of exploratory analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = [voted_primary.D.sum(), voted_primary.R.sum()]\n",
    "parties = [\"Democrat\", \"Republican\"]\n",
    "colors = [\"blue\", \"red\"]\n",
    "\n",
    "p = figure(x_range=parties, plot_height=350, title=\"Number of Politically Active Voters By Party\", toolbar_location=None, tools=\"\")\n",
    "p.vbar(x=parties, top=counts, width=0.9, alpha=0.5, fill_color=colors)\n",
    "p.xgrid.grid_line_color = None\n",
    "p.y_range.start = 0\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise(iterable):\n",
    "    a, b = itertools.tee(iterable)\n",
    "    next(b, None)\n",
    "    return zip(a, b)\n",
    "\n",
    "income_levels = [i*10000 for i in range(2, 12)]\n",
    "factors = list(itertools.chain(*[((f\"{i}-{j}\", \"R\"), (f\"{i}-{j}\", \"D\")) for i, j in pairwise(income_levels)]))\n",
    "incomes_R = [voted_primary[voted_primary.R & (voted_primary[\"AVG_INCOME\"] > i) & (voted_primary[\"AVG_INCOME\"] < j)].shape[0] for i, j in pairwise(income_levels)]\n",
    "incomes_D = [voted_primary[voted_primary.D & (voted_primary[\"AVG_INCOME\"] > i) & (voted_primary[\"AVG_INCOME\"] < j)].shape[0] for i, j in pairwise(income_levels)]\n",
    "incomes = list(itertools.chain(*zip(incomes_R, incomes_D)))\n",
    "colors = list(itertools.chain(*[(\"red\", \"blue\") for i, j in pairwise(income_levels)]))\n",
    "\n",
    "p = figure(x_range=FactorRange(*factors), plot_height=500, plot_width=1000, title=\"Income By Party\", toolbar_location=None, tools=\"\")\n",
    "p.vbar(x=factors, top=incomes, width=0.9, alpha=0.5, color=colors)\n",
    "p.y_range.start = 0\n",
    "p.x_range.range_padding = 0.1\n",
    "p.xaxis.axis_label = \"Incomes ($)\"\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_min, pop_max = voted_primary[\"POP_DENSITY\"].min(), voted_primary[\"POP_DENSITY\"].max()\n",
    "pop_levels = [0, 1000, 3000, np.inf] #np.linspace(pop_min, pop_max, 4)\n",
    "pop_designations = [\"rural\", \"suburban\", \"urban\"]\n",
    "\n",
    "factors = list(itertools.chain(*[((i, \"R\"), (i, \"D\")) for i in pop_designations]))\n",
    "pop_R = [voted_primary[voted_primary.R & (voted_primary[\"POP_DENSITY\"] > i) & (voted_primary[\"POP_DENSITY\"] < j)].shape[0] for i, j in pairwise(pop_levels)]\n",
    "pop_D = [voted_primary[voted_primary.D & (voted_primary[\"POP_DENSITY\"] > i) & (voted_primary[\"POP_DENSITY\"] < j)].shape[0] for i, j in pairwise(pop_levels)]\n",
    "pops = list(itertools.chain(*zip(pop_R, pop_D)))\n",
    "colors = list(itertools.chain(*[(\"red\", \"blue\") for i, j in pairwise(pop_levels)]))\n",
    "\n",
    "p = figure(x_range=FactorRange(*factors), plot_height=500, plot_width=1000, title=\"Population Level By Party\", toolbar_location=None, tools=\"\")\n",
    "p.vbar(x=factors, top=pops, width=0.9, alpha=0.5, color=colors)\n",
    "p.y_range.start = 0\n",
    "p.x_range.range_padding = 0.1\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_levels = [18, 25, 35, 45, 55, 65, 75, 85, 95, 100]\n",
    "\n",
    "factors = list(itertools.chain(*[((f\"{i}-{j}\", \"R\"), (f\"{i}-{j}\", \"D\")) for i, j in pairwise(age_levels)]))\n",
    "age_R = [voted_primary[voted_primary.R & (voted_primary[\"AGE\"] > i) & (voted_primary[\"AGE\"] < j)].shape[0] for i, j in pairwise(age_levels)]\n",
    "age_D = [voted_primary[voted_primary.D & (voted_primary[\"AGE\"] > i) & (voted_primary[\"AGE\"] < j)].shape[0] for i, j in pairwise(age_levels)]\n",
    "ages = list(itertools.chain(*zip(age_R, age_D)))\n",
    "colors = list(itertools.chain(*[(\"red\", \"blue\") for i, j in pairwise(age_levels)]))\n",
    "\n",
    "p = figure(x_range=FactorRange(*factors), plot_height=500, plot_width=1000, title=\"Age by Party\", toolbar_location=None, tools=\"\")\n",
    "p.vbar(x=factors, top=ages, width=0.9, alpha=0.5, color=colors)\n",
    "p.y_range.start = 0\n",
    "p.x_range.range_padding = 0.1\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate a couple more initeresting statistics from the 2018 midterm election:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_turnout(party, election, mask=None):\n",
    "    if mask is None:\n",
    "        return df_reduced.groupby([\"PARTY_AFFILIATION\"]).get_group(party).loc[:, election].notnull().sum() / (df_reduced[\"PARTY_AFFILIATION\"] == party).sum()\n",
    "    else:\n",
    "        return df_reduced.groupby([\"PARTY_AFFILIATION\"]).get_group(party).loc[mask, election].notnull().sum() / (df_reduced[\"PARTY_AFFILIATION\"][mask] == party).sum()\n",
    "    \n",
    "primary_turnouts = [get_turnout(party, 'PRIMARY-05/08/2018') for party in ['D', 'R']]\n",
    "parties = [\"Democrat\", \"Republican\"]\n",
    "colors = [\"blue\", \"red\"]\n",
    "\n",
    "p = figure(x_range=parties, plot_height=500, title=\"Primary Turnout By Party\", toolbar_location=None, tools=\"\")\n",
    "p.vbar(x=parties, top=primary_turnouts, width=0.9, alpha=0.5, fill_color=colors)\n",
    "p.xgrid.grid_line_color = None\n",
    "p.y_range.start = 0\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_turnouts = [get_turnout(party, 'GENERAL-11/06/2018') for party in ['D', 'R']]\n",
    "parties = [\"Democrat\", \"Republican\"]\n",
    "colors = [\"blue\", \"red\"]\n",
    "\n",
    "p = figure(x_range=parties, plot_height=500, title=\"General Election Turnout By Party\", toolbar_location=None, tools=\"\")\n",
    "p.vbar(x=parties, top=general_turnouts, width=0.9, alpha=0.5, fill_color=colors)\n",
    "p.xgrid.grid_line_color = None\n",
    "p.y_range.start = 0\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_levels = [18, 25, 35, 45, 55, 65, 75, 85, 95, 100]\n",
    "\n",
    "factors = list(itertools.chain(*[((f\"{i}-{j}\", \"R\"), (f\"{i}-{j}\", \"D\")) for i, j in pairwise(age_levels)]))\n",
    "age_R = [get_turnout('R', 'PRIMARY-05/08/2018', (df_reduced[\"AGE\"] > i) & (df_reduced[\"AGE\"] < j)) for i, j in pairwise(age_levels)]\n",
    "age_D = [get_turnout('D', 'PRIMARY-05/08/2018', (df_reduced[\"AGE\"] > i) & (df_reduced[\"AGE\"] < j)) for i, j in pairwise(age_levels)]\n",
    "ages = list(itertools.chain(*zip(age_R, age_D)))\n",
    "colors = list(itertools.chain(*[(\"red\", \"blue\") for i, j in pairwise(age_levels)]))\n",
    "\n",
    "p = figure(x_range=FactorRange(*factors), plot_height=500, plot_width=1000, title=\"Primary Election Turnout By Age\", toolbar_location=None, tools=\"\")\n",
    "p.vbar(x=factors, top=ages, width=0.9, alpha=0.5, color=colors)\n",
    "p.y_range.start = 0\n",
    "p.x_range.range_padding = 0.1\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_levels = [18, 25, 35, 45, 55, 65, 75, 85, 95, 100]\n",
    "\n",
    "factors = list(itertools.chain(*[((f\"{i}-{j}\", \"R\"), (f\"{i}-{j}\", \"D\")) for i, j in pairwise(age_levels)]))\n",
    "age_R = [get_turnout('R', 'GENERAL-11/06/2018', (df_reduced[\"AGE\"] > i) & (df_reduced[\"AGE\"] < j)) for i, j in pairwise(age_levels)]\n",
    "age_D = [get_turnout('D', 'GENERAL-11/06/2018', (df_reduced[\"AGE\"] > i) & (df_reduced[\"AGE\"] < j)) for i, j in pairwise(age_levels)]\n",
    "ages = list(itertools.chain(*zip(age_R, age_D)))\n",
    "colors = list(itertools.chain(*[(\"red\", \"blue\") for i, j in pairwise(age_levels)]))\n",
    "\n",
    "p = figure(x_range=FactorRange(*factors), plot_height=500, plot_width=1000, title=\"General Election Turnout By Age\", toolbar_location=None, tools=\"\")\n",
    "p.vbar(x=factors, top=ages, width=0.9, alpha=0.5, color=colors)\n",
    "p.y_range.start = 0\n",
    "p.x_range.range_padding = 0.1\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['AGE', 'AVG_INCOME', 'POP_DENSITY']\n",
    "target = 'D'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = voted_primary[features + ['R', 'D']].dropna().reset_index(drop=True)\n",
    "train_df, holdout_df = train_test_split(\n",
    "    model_df, test_size=0.1)\n",
    "\n",
    "train_df.reset_index(inplace=True)\n",
    "holdout_df.reset_index(inplace=True)\n",
    "\n",
    "(train_df.shape[0], holdout_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## def get_metrics(classifier, test_data, test_labels):\n",
    "    predicted_labels = classifier.predict(test_data)\n",
    "    accuracy = accuracy_score(test_labels, predicted_labels)\n",
    "    precision = precision_score(test_labels, predicted_labels)\n",
    "    recall = recall_score(test_labels, predicted_labels)\n",
    "    return accuracy, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RocPlot():\n",
    "    def __init__(self, train_df, test_df, features, target):\n",
    "        self.train_df = train_df\n",
    "        self.test_df = test_df\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "        self.auc_scores = {}\n",
    "        self.plot = figure(title=\"ROC Curves\", tools=\"\", width=900)\n",
    "        self.plot.legend.location = \"top_left\"\n",
    "    \n",
    "    def add(self, classifier, label, color, scaler = None):\n",
    "        if scaler != None:\n",
    "            train_data = scaler.transform(self.train_df[self.features])\n",
    "            test_data = scaler.transform(self.test_df[self.features])\n",
    "        else:\n",
    "            train_data = self.train_df[self.features]\n",
    "            test_data = self.test_df[self.features]\n",
    "        train_y = self.train_df[self.target]\n",
    "        test_y = self.test_df[self.target]\n",
    "        \n",
    "        classifier.fit(train_data, train_y)\n",
    "        y_prob = classifier.predict_proba(test_data)\n",
    "        \n",
    "        fpr, tpr, thresh = roc_curve(test_y, y_prob[:,1])\n",
    "        self.plot.line(fpr, tpr, color=color, line_width=2, legend=label)\n",
    "        self.plot.xaxis.axis_label = \"FPR\"\n",
    "        self.plot.yaxis.axis_label = \"TPR\"\n",
    "        auc = roc_auc_score(test_y, y_prob[:,1])\n",
    "        self.auc_scores[label] = auc\n",
    "    \n",
    "    def get_auc_scores(self):\n",
    "        return self.auc_scores\n",
    "    \n",
    "    def show(self):\n",
    "        show(self.plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced[features].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(classifier, data, features, target, param_grid, cv=5):\n",
    "    cv = GridSearchCV(estimator = classifier, param_grid = param_grid, cv = cv, verbose=2, n_jobs = -1, return_train_score=True)\n",
    "    cv.fit(data[features], data[target])\n",
    "    return (cv.cv_results_, cv.best_params_)\n",
    "\n",
    "def train_classifier_random(classifier, data, features, target, param_grid, cv=5, n_iter=10, random_state=42):\n",
    "    cv = RandomizedSearchCV(estimator = classifier, param_distributions = param_grid, n_iter = n_iter, cv = cv, verbose=2, random_state=random_state, n_jobs = -1, return_train_score=True)\n",
    "    cv.fit(data[features], data[target])\n",
    "    return (cv.cv_results_, cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_plot = RocPlot(train_df, holdout_df, features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = [0.001,0.01,0.1,1,10,100]\n",
    "penalty = ['l1', 'l2']\n",
    "\n",
    "grid = {'C': c,\n",
    "           'penalty': penalty}\n",
    "classifier = LogisticRegression()\n",
    "results, logistic_regression_best_params = train_classifier(classifier, train_df, features, target, grid)\n",
    "logistic_regression_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(**logistic_regression_best_params)\n",
    "classifier.fit(train_df[features], train_df[target])\n",
    "get_metrics(classifier, holdout_df[features], holdout_df[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_plot.add(classifier, \"Logistic Regression\", \"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples_split = [2, 5, 7, 10, 15, 20, 50, 60, 70, 80, 90, 100, 120, 150]\n",
    "max_depth = [3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "grid = {'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split}\n",
    "classifier = DecisionTreeClassifier()\n",
    "results, decision_tree_best_params = train_classifier(classifier, train_df, features, target, grid)\n",
    "decision_tree_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifier(**decision_tree_best_params)\n",
    "classifier.fit(train_df[features], train_df[target])\n",
    "get_metrics(classifier, holdout_df[features], holdout_df[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_plot.add(classifier, \"Decision Tree\", \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start = 50, stop = 2000, num = 10)]\n",
    "max_depth = [3, 4, 5, 6, 7, 8, 9, 10]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth.append(None)\n",
    "min_samples_split = [500, 750, 1000, 1250, 1500]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "classifier = RandomForestClassifier()\n",
    "results, random_forest_best_params = train_classifier_random(classifier, train_df, features, target, grid, cv=3, n_iter=10, random_state=42)\n",
    "random_forest_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(**random_forest_best_params)\n",
    "classifier.fit(train_df[features], train_df[target])\n",
    "get_metrics(classifier, holdout_df[features], holdout_df[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_plot.add(classifier, \"Random Forest\", \"green\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = [1, 0.5, 0.25, 0.1, 0.05, 0.01]\n",
    "n_estimators = [1, 2, 4, 8, 16, 32, 64, 100, 200]\n",
    "max_depth = np.linspace(1, 32, 32, endpoint=True)\n",
    "min_samples_split = np.linspace(0.1, 1.0, 10, endpoint=True)\n",
    "min_samples_leaf = np.linspace(0.1, 0.5, 5, endpoint=True)\n",
    "max_features = list(range(1,len(features)))\n",
    "\n",
    "grid = {'learning_rate': learning_rate,\n",
    "               'n_estimators': n_estimators,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'max_features': max_features}\n",
    "classifier = GradientBoostingClassifier()\n",
    "results, gradient_boosting_best_params = train_classifier_random(classifier, train_df, features, target, grid, cv=3, n_iter=100, random_state=42)\n",
    "gradient_boosting_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = GradientBoostingClassifier(**gradient_boosting_best_params)\n",
    "classifier.fit(train_df[features], train_df[target])\n",
    "get_metrics(classifier, holdout_df[features], holdout_df[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_plot.add(classifier, \"Gradient Boosting\", \"purple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_sizes=[(100,100,100)]\n",
    "activation = ['identity', 'logistic', 'tanh', 'relu']\n",
    "solver = ['lbfgs', 'sgd', 'adam']\n",
    "learning_rate = ['constant', 'invscaling', 'adaptive']\n",
    "\n",
    "grid = {\n",
    "    'hidden_layer_sizes': hidden_layer_sizes,\n",
    "    'activation': activation,\n",
    "    'solver': solver,\n",
    "    'learning_rate': learning_rate\n",
    "}\n",
    "\n",
    "scaler = StandardScaler()\n",
    "classifier = MLPClassifier()\n",
    "scaler.fit(train_df[features])\n",
    "transformed_train_df = scaler.transform(train_df[features])\n",
    "cv = RandomizedSearchCV(estimator = classifier, param_distributions = grid, n_iter = 10, cv = 5, verbose=2, random_state=42, n_jobs = -1, return_train_score=True)\n",
    "cv.fit(transformed_train_df, train_df[target])\n",
    "mlp_best_params = cv.best_params_\n",
    "mlp_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = MLPClassifier(**mlp_best_params)\n",
    "classifier.fit(transformed_train_df, train_df[target])\n",
    "transformed_holdout_df = scaler.transform(holdout_df[features])\n",
    "get_metrics(classifier, transformed_holdout_df, holdout_df[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_plot.add(classifier, \"Multilayer Perceptron\", \"orange\", scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ROC plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_plot.get_auc_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: \n",
    "\n",
    "Logistic regression appears to be the worst-performing model. Decision trees, random forests and gradient boosting appear to exhibit the same performance, so we are going to choose the decision tree classiffier for our task. The accuracy is around 68%, which is not terrible given the limited number of features and the assumptions that are being made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voter Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before using our classification model, we need to narrow our data to a pool of voters who are most likely to be swayed by our campaign letters. It makes no sense to target voters who are registered with the opposite party, since most are not even going to read them. Similarly, it makes little sense to target voters who are registered with our party and vote regularly, since their votes are most likely already secured. Therefore, we are going to include those voters who are not affiliated with either party and the voters who are registered with our party but have not voted for at least two election cycles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_recent_voter = df_reduced[['PRIMARY-03/15/2016', 'GENERAL-06/07/2016', 'PRIMARY-09/13/2016',\n",
    "       'GENERAL-11/08/2016', 'PRIMARY-05/02/2017', 'PRIMARY-09/12/2017',\n",
    "       'GENERAL-11/07/2017', 'PRIMARY-05/08/2018', 'GENERAL-08/07/2018',\n",
    "       'GENERAL-11/06/2018']].notnull().sum(1) == 0\n",
    "target_party = df_reduced['PARTY_AFFILIATION'] == target\n",
    "not_affiliated = df_reduced['PARTY_AFFILIATION'].isnull()\n",
    "\n",
    "possible_choices = df_reduced[(target_party & not_recent_voter) | not_affiliated]\n",
    "possible_choices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifier(**decision_tree_best_params)\n",
    "classifier.fit(voted_primary[features], voted_primary[target])\n",
    "predicted = classifier.predict_proba(possible_choices[features])\n",
    "possible_choices[f\"P({target})\"] = predicted[:, 1]\n",
    "possible_choices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = possible_choices.nlargest(100000, [f\"P({target})\"])\n",
    "selected[features].describe().loc['mean', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_histogram(data, title, x_axis_label, bins):\n",
    "    hist, edges = np.histogram(data, density=True, bins=bins)\n",
    "    p = figure(title=title, tools=\"\")\n",
    "    p.quad(top=hist, bottom=0, left=edges[:-1], right=edges[1:], line_color=\"white\", alpha=0.5)\n",
    "    p.xaxis.axis_label = x_axis_label\n",
    "    p.yaxis.visible = False\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "p = make_histogram(selected[f\"P({target})\"], f\"Prediction Probabilities ({target})\", \"Probability\", 10)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad - almost all of the selected voters were classified with the probability of over 75%. We can be confident that we are not wasting our resources by sending them letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_p = make_histogram(selected[\"AGE\"], f\"Age distribution ({target})\", \"Age\", 30)\n",
    "show(age_p) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_density_p = make_histogram(selected[\"POP_DENSITY\"], f\"Population density distribution ({target})\", \"Population density\", 20)\n",
    "show(pop_density_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_p = make_histogram(selected[selected[\"AVG_INCOME\"] < 150000][\"AVG_INCOME\"], f\"Income distribution ({target})\", \"Income\", 30)\n",
    "show(income_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like if we target Democrats, our model selects mostly younger, less affluent voters who reside in suburban and urban areas, which agrees with what we learned from our exploratory analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
